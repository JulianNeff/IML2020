{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task4_aurel.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulianNeff/IML2020/blob/master/task4_aurel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk_78rCg-C5K",
        "colab_type": "code",
        "outputId": "2a8f37d1-639b-4a76-ab50-0081433586da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "from scipy.fftpack import fft\n",
        "# Imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# Fix random seed\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHkyWPfV-YxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Read in data and create datasets\n",
        "'''\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_eeg1_train = pd.read_csv('drive/My Drive/AML/Task4/train_eeg1.csv')\n",
        "df_eeg2_train = pd.read_csv('drive/My Drive/AML/Task4/train_eeg2.csv')\n",
        "df_emg_train = pd.read_csv('drive/My Drive/AML/Task4/train_emg.csv')\n",
        "df_y_train = pd.read_csv('drive/My Drive/AML/Task4/train_labels.csv')\n",
        "df_eeg1_test = pd.read_csv('drive/My Drive/AML/Task4/test_eeg1.csv')\n",
        "df_eeg2_test = pd.read_csv('drive/My Drive/AML/Task4/test_eeg2.csv')\n",
        "df_emg_test = pd.read_csv('drive/My Drive/AML/Task4/test_emg.csv')\n",
        "# Train and validation data sets\n",
        "eeg1_train_headers = df_eeg1_train.columns\n",
        "eeg2_train_headers = df_eeg2_train.columns\n",
        "emg_train_headers = df_emg_train.columns\n",
        "\n",
        "eeg1_train_all = df_eeg1_train[eeg1_train_headers[1:]].values\n",
        "eeg2_train_all = df_eeg2_train[eeg1_train_headers[1:]].values\n",
        "emg_train_all = df_emg_train[eeg1_train_headers[1:]].values\n",
        "y_train_all = df_y_train['y'].values\n",
        "\n",
        "eeg1_train_raw, eeg1_validate_raw, eeg2_train_raw, eeg2_validate_raw, emg_train_raw, emg_validate_raw, y_train, y_validate = train_test_split(\n",
        "    eeg1_train_all, eeg2_train_all, emg_train_all, y_train_all, test_size=0.1)\n",
        "\n",
        "# Test data set\n",
        "#id_test = df_eeg1_test['id']\n",
        "eeg1_test_headers = df_eeg1_test.columns\n",
        "eeg2_test_headers = df_eeg2_test.columns\n",
        "emg_test_headers = df_emg_test.columns\n",
        "eeg1_test_all = df_eeg1_test[eeg1_test_headers[1:]].values\n",
        "eeg2_test_all = df_eeg2_test[eeg2_test_headers[1:]].values\n",
        "emg_test_all = df_emg_test[emg_test_headers[1:]].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpD7gilbnZ9V",
        "colab_type": "code",
        "outputId": "028b3c5d-575b-41b9-edcf-cd3ed9a2e5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Feature Extraction: Alpha, Beta, Gamma, ..., Power spectrum\n",
        "#Sample Frequency = sample rate / amount of samples\n",
        "#--> 4s segments, 512 samples?\n",
        "#plt.plot(emg_train_raw, y_train=1)\n",
        "#plt.plot(eeg1_train_raw, y_train[0])\n",
        "#plt.plot(eeg1_train_raw, y_train[0])\n",
        "\n",
        "#plt.figure(figsize=(12,4))\n",
        "#plt.plot(X_train[100])\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%plt.plot` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNd-_hmkzXKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fft_eeg1_train=fft(eeg1_train_raw)\n",
        "fft_eeg1_val=fft(eeg1_validate_raw)\n",
        "fft_eeg2_train=fft(eeg2_train_raw)\n",
        "fft_eeg2_val=fft(eeg2_validate_raw)\n",
        "fft_emg_train=fft(emg_train_raw)\n",
        "fft_emg_val=fft(emg_validate_raw)\n",
        "#Test\n",
        "fft_eeg1_test=fft(eeg1_test_all)\n",
        "fft_eeg2_test=fft(eeg2_test_all)\n",
        "fft_emg_test=fft(emg_test_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7319gnC4OWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of samplepoints\n",
        "N = 512\n",
        "# sample spacing\n",
        "#T = 1.0 / 800.0\n",
        "#x = np.linspace(0.0, N*T, N)\n",
        "#xf = np.linspace(0.0, 1.0/(2.0*T), N/2)\n",
        "\n",
        "#fig, ax = plt.subplots()\n",
        "#ax.plot(xf, 2.0/N * np.abs(yf[:N//2]))\n",
        "#plt.show()\n",
        "#plt.plot(fft_eeg1_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSUulmXpIcVK",
        "colab_type": "code",
        "outputId": "c1969144-286b-4fc0-8f9a-e1e64131e72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "'''\n",
        "Feature extraction\n",
        "'''\n",
        "\n",
        "def extract_features(X, y=None):\n",
        "  n_rows = X.shape[0]\n",
        "  i_rows = 0\n",
        "  X_features = []\n",
        "  for row in X:\n",
        "    data = row[~np.isnan(row)]\n",
        "    out = ecg.ecg(signal=data, sampling_rate=300, show=False).as_dict()\n",
        "    templates = out['templates']\n",
        "    heart_rate = out['heart_rate']\n",
        "    \n",
        "    features = np.nan_to_num([heart_rate_mean, heart_rate_std, \n",
        "                              template_std_mean, template_std_std,\n",
        "                              p_mean, q_mean, r_mean, s_mean, t_mean, \n",
        "                              p_std, q_std, r_std, s_std, t_std, \n",
        "                              p_arg_mean, q_arg_mean, s_arg_mean, t_arg_mean,\n",
        "                              p_arg_std, q_arg_std, s_arg_std, t_arg_std,\n",
        "                              mean_mean])\n",
        "    X_features.append(features)\n",
        "    if y is not None:\n",
        "      print(\"{} / {} - class {}\".format(i_rows, n_rows, y[i_rows]))\n",
        "    else:\n",
        "      print(\"{} / {}\".format(i_rows, n_rows))\n",
        "    i_rows += 1\n",
        "\n",
        "  # Normalize\n",
        "  X_features = np.array(X_features)\n",
        "  m = np.nanmean(X_features, axis=0)\n",
        "  X_features = X_features - m\n",
        "  s = np.nanstd(X_features, axis=0)\n",
        "  X_features = X_features / s\n",
        "  \n",
        "  return X_features\n",
        "\n",
        "X_train = extract_features(X_train_raw, y_train)\n",
        "X_validate = extract_features(X_validate_raw)\n",
        "X_test = extract_features(X_test_raw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c1b29cf7668e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mX_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mX_validate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_raw' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhCEIY6s-dCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Pre-process data.\n",
        "'''\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Normalize\n",
        "# Needs to be done in two steps instead of one because of overflow\n",
        "m = np.nanmean(X_train, axis=0)\n",
        "X_train = X_train - m\n",
        "n = np.nanmean(X_test, axis=0)\n",
        "X_test  = X_test - n\n",
        "k = np.nanmean(X_validate, axis=0)\n",
        "X_validate = X_validate - k\n",
        "s1 = np.nanstd(X_train, axis=0)\n",
        "s2 = np.nanstd(X_test, axis=0)\n",
        "s3 = np.nanstd(X_validate, axis=0)\n",
        "X_train = X_train / s1\n",
        "X_test  = X_test / s2\n",
        "X_validate = X_validate / s3\n",
        "\n",
        "# Replace NaN\n",
        "strategy = 'constant'\n",
        "X_train = SimpleImputer(strategy=strategy).fit_transform(X_train)\n",
        "X_validate = SimpleImputer(strategy=strategy).fit_transform(X_validate)\n",
        "X_test = SimpleImputer(strategy=strategy).fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4QTlLoAimiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Feature selection\n",
        "'''\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "select_k_best = SelectKBest(f_regression, k=600)\n",
        "select_k_best.fit(X_train, y_train)\n",
        "X_train = select_k_best.transform(X_train)\n",
        "X_validate = select_k_best.transform(X_validate)\n",
        "X_test = select_k_best.transform(X_test)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlILQkq1-eZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Create model and train\n",
        "'''\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "#model = LogisticRegressionCV(cv=5, random_state=0, multi_class='multinomial')\n",
        "model = svm.SVC(C=1,kernel='rbf', \n",
        "                class_weight='balanced',\n",
        "                probability=True,\n",
        "                decision_function_shape='ovo')\n",
        "#model = RFECV(estimator=svc, step=1, cv=StratifiedKFold(5))\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCydUmd--gsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Evaluation\n",
        "'''\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "y_train_predict = model.predict(X_train)\n",
        "score = balanced_accuracy_score(y_train, y_train_predict)\n",
        "print('BMAC score of training set:   {}'.format(score))\n",
        "y_validate_predict = model.predict(X_validate)\n",
        "score = balanced_accuracy_score(y_validate, y_validate_predict)\n",
        "print('BMAC score of validation set: {}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIxH1GZy-lGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "'''\n",
        "Predict on test data and write to file.\n",
        "'''\n",
        "\n",
        "y_test = model.predict(X_test)\n",
        "df_pred = pd.DataFrame({'id': id_test, 'y': y_test})\n",
        "df_pred.to_csv('submission4.csv', index=False)\n",
        "!cp submission4.csv drive/My\\ Drive/AML/Task1\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}